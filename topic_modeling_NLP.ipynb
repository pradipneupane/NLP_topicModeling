{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk.corpus as nltkcorpus\n",
    "from gensim.models import CoherenceModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "                                                content  target  \\\n0     From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n1     From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n10    From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n100   From: tchen@magnus.acs.ohio-state.edu (Tsung-K...       6   \n1000  From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...       2   \n\n                 target_names  \n0                   rec.autos  \n1       comp.sys.mac.hardware  \n10            rec.motorcycles  \n100              misc.forsale  \n1000  comp.os.ms-windows.misc  ",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "print(df.head())\n",
    "'''\n",
    "this content column in this dataframe has lots of new lines, emails, white spaces, etc. Lets\n",
    "do some pre-processing using regular expressions\n",
    "'''\n",
    "\n",
    "content = df.content.values.tolist()\n",
    "content = [re.sub(r'\\S*@\\S*\\s?', '', sent) for sent in content]\n",
    "content = [re.sub(r'\\s+', ' ', sent) for sent in content]\n",
    "content = [re.sub(r\"\\'\", \"\", sent) for sent in content]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\pradi\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# further pre-processing like tokenization and other stuffs using genism\n",
    "def tokenize(sentences):\n",
    "    for line in sentences:\n",
    "        yield simple_preprocess(str(line), deacc= True) # deacc= true removes punctuations\n",
    "\n",
    "\n",
    "process_content = list(tokenize(content))\n",
    "# there were 11314 rows. Lets print first row to see how the data has been processed\n",
    "print(process_content[:1])\n",
    "\n",
    "'''\n",
    "next step is to Build the bigram and trigram models using genism\n",
    "Bigrams means 2 words frequently occurring together in the document. Trigrams means 3 words frequently occurring.\n",
    "'''\n",
    "bigram = gensim.models.Phrases(process_content, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[process_content], threshold=100)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mode = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mode = gensim.models.phrases.Phraser(trigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# futher pre-processing by removing stop words, Make Bigrams and Lemmatize the words\n",
    "stop_words = nltkcorpus.stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def stopwords_remove(text):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in text]\n",
    "\n",
    "def make_bigrams(text):\n",
    "    return [bigram_mode[doc] for doc in text]\n",
    "\n",
    "def make_trigrams(text):\n",
    "    return [trigram_mode[bigram_mode[doc]] for doc in text]\n",
    "\n",
    "def do_lemmatization(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']): # this allowed postages comes from spacy   \n",
    "    texts_out = []\n",
    "    for sent in text:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[['where', 's', 'thing', 'car', 'nntp_poste', 'host', 'umd', 'organization', 'university', 'maryland_college', 'park', 'line', 'wonder', 'anyone', 'could', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'bricklin', 'door', 'really', 'small', 'addition', 'front_bumper', 'separate', 'rest', 'body', 'know', 'anyone', 'tellme', 'model', 'name', 'engine', 'specs', 'year', 'production', 'car', 'make', 'history', 'info', 'funky', 'look', 'car', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst']]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# lets pre-process using above function\n",
    "content_withoutStopwords = stopwords_remove(process_content)\n",
    "content_bigram = make_bigrams(content_withoutStopwords)\n",
    "\n",
    "# lets lemmatize the text allowing only noun, adj, vb, adv\n",
    "content_lemmatize = do_lemmatization(content_bigram, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(content_lemmatize[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Finally lets create dictionary and corpus which is needed for the LDA topic modelling\n",
    "id2word = corpora.Dictionary(content_lemmatize)\n",
    "\n",
    "_corpus = [id2word.doc2bow(text) for text in content_lemmatize]\n",
    "\n",
    "# next step is to train the LDA model from gensim\n",
    "\n",
    "_ldamodel = gensim.models.ldamodel.LdaModel(corpus= _corpus,\n",
    "                                            id2word= id2word,\n",
    "                                            num_topics=20,\n",
    "                                            random_state=50,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=150,\n",
    "                                            passes=10,\n",
    "                                            alpha='auto',\n",
    "                                            per_word_topics= True\n",
    "                                            )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Coherence Score: ",
      " ",
      "0.5397608545029745",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# computing the coherence score to judge how good a given topic model is\n",
    "\n",
    "_coherence_model_lda = CoherenceModel(model=_ldamodel, texts=content_lemmatize, dictionary=id2word,\n",
    "                                      coherence='c_v' )\n",
    "\n",
    "coherence_lda = _coherence_model_lda.get_coherence()\n",
    "\n",
    "print('Coherence Score: ', coherence_lda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "After this, we can do further tasks like\n",
    "visualizing the topic words,\n",
    "improving the coherence score,\n",
    "Find the most representative document for each topic,\n",
    "Finding the dominant topic in each sentence,\n",
    "and many more complex NLP modeling.  \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}